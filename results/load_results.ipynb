{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6dcd5-7d56-4a07-a928-4b309409c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3932ade7-9a86-4550-8af3-08ff5d4399ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"Cora\": np.zeros((2, ))} # fill with rest of datasets eg. {\"Cora\": np.zeros((2, )), \"Cora_ML\": np.zeros((2, )), ...}\n",
    "model_nids = {'MLP_LLPE': {'llpe': 256}} # fill with rest of models eg. {'SAGE_LLPE': {'llpe': 256}, 'GT_LLPE': {'llpe': 256}}\n",
    "model_results = {'MLP_LLPE': {'llpe': copy.deepcopy(datasets)}} # fill with rest of models eg. {'SAGE_LLPE': {'llpe': copy.deepcopy(datasets)}, ...}\n",
    "\n",
    "names_print = []\n",
    "results_print = {\"Cora\": []} # fill with rest of models datasets eg. {'Cora': [], 'Cora_ML': [], ...}\n",
    "results_ranks = {\"Cora\": []} # fill with rest of models datasets eg. {'Cora': [], 'Cora_ML': [], ...}\n",
    "results_hist = {\"Cora\": []} # fill with rest of models datasets eg. {'Cora': [], 'Cora_ML': [], ...}\n",
    "save_path = './benchmarks'\n",
    "for model in model_results.keys(): \n",
    "    for data in results_print.keys(): \n",
    "        for pos_enc in model_results[model].keys(): \n",
    "            if pos_enc in ['lap-fkf', 'llpe']: \n",
    "                best_acc_mean, best_acc_std, hist = get_results_benchmarks(save_path, data, model, pos_enc, total_ids=model_nids[model][pos_enc], verbose=True, last_id=1, history=True)\n",
    "                results_hist[data].append(hist)\n",
    "            else: \n",
    "                best_acc_mean, best_acc_std = get_results_benchmarks(save_path, data, model, pos_enc, total_ids=model_nids[model][pos_enc], verbose=False, last_id=1)\n",
    "            \n",
    "            model_results[model][pos_enc][data][0], model_results[model][pos_enc][data][1] = best_acc_mean, best_acc_std\n",
    "            results_print[data].append(f\"{best_acc_mean*100:.2f} \\u00B1 {best_acc_std*100:.2f}\")\n",
    "            results_ranks[data].append(best_acc_mean)\n",
    "\n",
    "names_print = []\n",
    "for model in model_results.keys(): \n",
    "    for pos_enc in model_results[model].keys(): \n",
    "        names_print.append(f'{model} {pos_enc}')\n",
    "\n",
    "for data in results_print.keys(): \n",
    "    results_print[data][-1] += f\"({np.sum(results_hist[data][-1]>results_hist[data][0])}/10)\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“env”",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
